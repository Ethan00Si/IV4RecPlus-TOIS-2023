lr: 0.0001
min_lr: 0.00001
weight_decay: 0.00000001 # l2 norm
patience: 5 # Number of epochs with no improvement after which learning rate will be reduced
es_patience: 5 #patience for early stop

input_emb_size: 768 #bert size
item_dim: 64
hid_units: [200, 80, 1]
dropout: 0.1

l2 : 0.0000001

IV_NET:

  lambda: 0.01
  item_IV_NET:
    hid_units: [128, 64]
    dropout: 0.1

    lambda: 0.01



item_Agg:
  input_dim: 128
  hid_units: [64, 16, 4, 1]
